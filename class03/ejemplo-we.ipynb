{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clase ST7017 NLP Aplicado\n",
    "# diferentes ejercicios de word embeddings para la lectura 03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5G8eliHN5gl"
   },
   "outputs": [],
   "source": [
    "# representación clásica en BoW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\"el gato está en la casa\", \"el perro está en el jardín\"]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.toarray())\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # representación clásica en word2vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    [\"el\", \"gato\", \"está\", \"en\", \"la\", \"casa\"],\n",
    "    [\"el\", \"perro\", \"está\", \"en\", \"el\", \"jardín\"]\n",
    "]\n",
    "model = Word2Vec(sentences, vector_size=50, window=2, min_count=1, sg=1)\n",
    "\n",
    "print(model.wv[\"gato\"])\n",
    "print(model.wv.similarity(\"gato\", \"perro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de modelos preentrenados\n",
    "# GloVe\n",
    "\n",
    "from gensim.downloader import load\n",
    "model = load(\"glove-wiki-gigaword-50\")  # vectores de 50 dimensiones\n",
    "print(model[\"king\"])\n",
    "print(model.most_similar(\"king\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model[\"python\"])\n",
    "print(model.most_similar(\"python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualización en 2D \n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = [\"king\", \"queen\", \"man\", \"women\"]\n",
    "vectors = [model[w] for w in words]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(vectors)\n",
    "\n",
    "for word, (x, y) in zip(words, coords):\n",
    "    plt.scatter(x, y)\n",
    "    plt.text(x+0.01, y+0.01, word)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejercicio de clase:\n",
    "'''\n",
    "Ejemplo1:\n",
    "Dado un conjunto de palabras ‘similares’ en contexto, detectar las palabras fuera del contexto:\n",
    "palabras = [\"pera\", \"piña\", \"papaya\", \"carro\"]\n",
    "\n",
    "respuesta: \"carro\"\n",
    "\n",
    "palabras = [\"peach\", \"pineapple\", \"papaya\", \"car\"]\n",
    "\n",
    "respuesta: \"car\"\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar modelo preentrenado glove\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "# escoja un modelo:\n",
    "\n",
    "# modelo Glove\n",
    "#model = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "# modelo word2vec\n",
    "\n",
    "# model = api.load(\"word2vec-google-news-300\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palabras:\n",
    "\n",
    "# prueba con palabras en español y con palabras en inglés y analice los resultados\n",
    "\n",
    "# palabras en español\n",
    "#palabras = [\"pera\", \"piña\", \"papaya\", \"carro\"]\n",
    "\n",
    "# palabras en ingles\n",
    "palabras = [\"peach\", \"pineapple\", \"papaya\", \"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar las palabras en el modelo:\n",
    "\n",
    "palabras_validas = [w for w in palabras if w in model]\n",
    "print(palabras_validas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular distancias al centroide de los 4 embeddings\n",
    "\n",
    "import numpy as np\n",
    "vectors = [model[w] for w in palabras_validas]\n",
    "print(vectors)\n",
    "centroid = np.mean(vectors, axis=0)\n",
    "\n",
    "distancias = [np.linalg.norm(model[w] - centroid) for w in palabras_validas]\n",
    "outlier = palabras_validas[np.argmax(distancias)]\n",
    "print(\"Palabra fuera de contexto:\", outlier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering con representación de embeddings y modelos clásicos no supervisados de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descargar y descomprimir modelo fasttext con corpus en español\n",
    "# 1.3 GB\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
    "\n",
    "# 4.5 GB\n",
    "!gunzip cc.es.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el modelo desde el archivo descargado previamente\n",
    "import gensim\n",
    "\n",
    "# Cargar modelo FastText para español (debe estar descargado)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"cc.es.300.vec\", binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = [\n",
    "    # objetos de casa\n",
    "    \"mueble\", \"nevera\", \"lavadora\", \"silla\", \"sofa\", \"tv\",\n",
    "    # colores\n",
    "    \"rojo\", \"amarillo\", \"verde\", \"azul\", \"gris\", \"negro\",\n",
    "    # Vehículos\n",
    "    \"auto\", \"camión\", \"moto\", \"bicicleta\", \"avión\", \"barco\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar que las palabras si estén en el corpus del modelo, filtrar las que no están\n",
    "X = [model[word] for word in palabras if word in model]\n",
    "palabras_filtradas = [word for word in palabras if word in model]\n",
    "print(palabras_filtradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutar un modelo clásico de kmeans con 3 grupos\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 3  # número esperado de grupos\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar en 2D grupos\n",
    "# se utiliza PCA para poder proyectar en un espacio 2D vectores densos y conservar las relaciones de distancia\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reducción de dimensión\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(X)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i, word in enumerate(palabras_filtradas):\n",
    "    plt.scatter(coords[i, 0], coords[i, 1], c=f\"C{labels[i]}\")\n",
    "    plt.text(coords[i, 0] + 0.01, coords[i, 1] + 0.01, word)\n",
    "plt.title(\"Visualización de distancias WE+PCA+K-Means)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analice los resultados y plantee otro dataset de palabras que SI permita tener 3 grupos bien identificados\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3WVJcCdtoHj7SiCYFiqJj",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
